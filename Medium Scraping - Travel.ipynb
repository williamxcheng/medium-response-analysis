{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tools\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_urls = {\n",
    "    'Travel': 'https://medium.com/tag/travel/archive/{0}/{1:02d}/{2:02d}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "selected_days = [i for i in range(1, 48)] #Every day of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_day(day):\n",
    "    # if it is a leap year use month_days = [31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    m = 0\n",
    "    d = 0\n",
    "    while day > 0:\n",
    "        d = day\n",
    "        day -= month_days[m]\n",
    "        m += 1\n",
    "    return (m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claps(claps_str):\n",
    "    if (claps_str is None) or (claps_str == '') or (claps_str.split is None):\n",
    "        return 0\n",
    "    split = claps_str.split('K')\n",
    "    claps = float(split[0])\n",
    "    claps = int(claps*1000) if len(split) == 2 else int(claps)\n",
    "    return claps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-01\n",
      "2022-01-02\n",
      "2022-01-03\n",
      "2022-01-04\n",
      "2022-01-05\n",
      "2022-01-06\n",
      "2022-01-07\n",
      "2022-01-08\n",
      "2022-01-09\n",
      "2022-01-10\n",
      "2022-01-11\n",
      "2022-01-12\n",
      "2022-01-13\n",
      "2022-01-14\n",
      "2022-01-15\n",
      "2022-01-16\n",
      "2022-01-17\n",
      "2022-01-18\n",
      "2022-01-19\n",
      "2022-01-20\n",
      "2022-01-21\n",
      "2022-01-22\n",
      "2022-01-23\n",
      "2022-01-24\n",
      "2022-01-25\n",
      "2022-01-26\n",
      "2022-01-27\n",
      "2022-01-28\n",
      "2022-01-29\n",
      "2022-01-30\n",
      "2022-01-31\n",
      "2022-02-01\n",
      "2022-02-02\n",
      "2022-02-03\n",
      "2022-02-04\n",
      "2022-02-05\n",
      "2022-02-06\n",
      "2022-02-07\n",
      "2022-02-08\n",
      "2022-02-09\n",
      "2022-02-10\n",
      "2022-02-11\n",
      "2022-02-12\n",
      "2022-02-13\n",
      "2022-02-14\n",
      "2022-02-15\n",
      "2022-02-16\n"
     ]
    }
   ],
   "source": [
    "articles_data = []\n",
    "article_id = 0\n",
    "n = len(selected_days)\n",
    "for d in selected_days:\n",
    "    month, day = convert_day(d)\n",
    "    date = '{0}-{1:02d}-{2:02d}'.format(year, month, day) \n",
    "    print(f'{date}')\n",
    "    for tag, url in tag_urls.items(): \n",
    "        response = requests.get(url.format(year, month, day), allow_redirects=True)\n",
    "        if not response.url.startswith(url.format(year, month, day)):\n",
    "            continue\n",
    "        page = response.content\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        articles = soup.find_all(\n",
    "            \"div\",\n",
    "            class_=\"postArticle postArticle--short js-postArticle js-trackPostPresentation js-trackPostScrolls\")\n",
    "        \n",
    "        for article in articles:\n",
    "            \n",
    "            title = article.find(\"h3\", class_=\"graf--title\")\n",
    "            if title is None:\n",
    "                continue\n",
    "            title = title.contents[0]\n",
    "            \n",
    "            author = article.find_all(\"a\")[0]['href'].split('?')[0].split('@')[1]\n",
    "            author_url = article.find_all(\"a\")[0]['href'].split('?')[0]\n",
    "            \n",
    "            subtitle = article.find(\"h4\", class_=\"graf--subtitle\")\n",
    "            subtitle = subtitle.contents[0] if subtitle is not None else ''\n",
    "            \n",
    "            article_url = article.find_all(\"a\")[3]['href'].split('?')[0]\n",
    "            \n",
    "            reading_time = article.find(\"span\", class_=\"readingTime\")\n",
    "            reading_time = 0 if reading_time is None else int(reading_time['title'].split(' ')[0])\n",
    "            \n",
    "            responses = article.find_all(\"a\")\n",
    "            if len(responses) == 7:\n",
    "                responses = responses[6].contents[0].split(' ')\n",
    "                if len(responses) == 0:\n",
    "                    responses = 0\n",
    "                else:\n",
    "                    responses = responses[0]\n",
    "            else:\n",
    "                responses = 0\n",
    "                \n",
    "            articles_data.append([article_url, title,\n",
    "                         author, author_url,\n",
    "                         subtitle, responses,\n",
    "                         reading_time, tag, date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform article data into panda dataframe.\n",
    "medium_df = pd.DataFrame(articles_data, columns=[\n",
    "    'url', 'title', 'author', 'author_page',\n",
    "    'subtitle', 'responses', 'reading_time',\n",
    "    'tag', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4906, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_df = medium_df.drop_duplicates(subset=['url', 'title'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4906, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>author_page</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>responses</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://medium.com/@anne.bonfert/i-got-stitche...</td>\n",
       "      <td>I Got Stitches in Paradise</td>\n",
       "      <td>anne.bonfert</td>\n",
       "      <td>https://medium.com/@anne.bonfert</td>\n",
       "      <td>Because I slipped on the tropical cliffs</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://medium.com/jtv-insights/2021-year-in-r...</td>\n",
       "      <td>2021 Year in review</td>\n",
       "      <td>amy_burr</td>\n",
       "      <td>https://medium.com/@amy_burr</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://medium.com/@cassady-fendlay/the-nomad-...</td>\n",
       "      <td>The Nomad Year</td>\n",
       "      <td>cassady-fendlay</td>\n",
       "      <td>https://medium.com/@cassady-fendlay</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://medium.com/travel-experiences/the-one-...</td>\n",
       "      <td>The one before the Taj Mahal</td>\n",
       "      <td>shrinathv</td>\n",
       "      <td>https://medium.com/@shrinathv</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://medium.com/@stephencasmier/space-and-d...</td>\n",
       "      <td>Hearing \"space and disjointed shit\" while flyi...</td>\n",
       "      <td>stephencasmier</td>\n",
       "      <td>https://medium.com/@stephencasmier</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>https://medium.com/@hubpost/what-does-travel-m...</td>\n",
       "      <td>What does travel mean to you ?</td>\n",
       "      <td>hubpost</td>\n",
       "      <td>https://medium.com/@hubpost</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>https://medium.com/@itsshirleygreen/planning-t...</td>\n",
       "      <td>[Planning travel around this season? Here are ...</td>\n",
       "      <td>itsshirleygreen</td>\n",
       "      <td>https://medium.com/@itsshirleygreen</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>https://medium.com/@tratomaseliasgonzalezbenit...</td>\n",
       "      <td>Realiza viajes en automóvil</td>\n",
       "      <td>tratomaseliasgonzalezbenitez</td>\n",
       "      <td>https://medium.com/@tratomaseliasgonzalezbenitez</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>https://medium.com/@alexjones8285-86083/ten-pl...</td>\n",
       "      <td>[Ten places not to miss when visiting Seychelles]</td>\n",
       "      <td>alexjones8285-86083</td>\n",
       "      <td>https://medium.com/@alexjones8285-86083</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>https://medium.com/@gomezpai/%D0%B4%D0%B5%D1%8...</td>\n",
       "      <td>“Деттержент химик эремәләр” лабораториясеннән ...</td>\n",
       "      <td>gomezpai</td>\n",
       "      <td>https://medium.com/@gomezpai</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel</td>\n",
       "      <td>2022-02-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4906 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0     https://medium.com/@anne.bonfert/i-got-stitche...   \n",
       "1     https://medium.com/jtv-insights/2021-year-in-r...   \n",
       "2     https://medium.com/@cassady-fendlay/the-nomad-...   \n",
       "3     https://medium.com/travel-experiences/the-one-...   \n",
       "4     https://medium.com/@stephencasmier/space-and-d...   \n",
       "...                                                 ...   \n",
       "4901  https://medium.com/@hubpost/what-does-travel-m...   \n",
       "4902  https://medium.com/@itsshirleygreen/planning-t...   \n",
       "4903  https://medium.com/@tratomaseliasgonzalezbenit...   \n",
       "4904  https://medium.com/@alexjones8285-86083/ten-pl...   \n",
       "4905  https://medium.com/@gomezpai/%D0%B4%D0%B5%D1%8...   \n",
       "\n",
       "                                                  title  \\\n",
       "0                            I Got Stitches in Paradise   \n",
       "1                                   2021 Year in review   \n",
       "2                                        The Nomad Year   \n",
       "3                          The one before the Taj Mahal   \n",
       "4     Hearing \"space and disjointed shit\" while flyi...   \n",
       "...                                                 ...   \n",
       "4901                     What does travel mean to you ?   \n",
       "4902  [Planning travel around this season? Here are ...   \n",
       "4903                        Realiza viajes en automóvil   \n",
       "4904  [Ten places not to miss when visiting Seychelles]   \n",
       "4905  “Деттержент химик эремәләр” лабораториясеннән ...   \n",
       "\n",
       "                            author  \\\n",
       "0                     anne.bonfert   \n",
       "1                         amy_burr   \n",
       "2                  cassady-fendlay   \n",
       "3                        shrinathv   \n",
       "4                   stephencasmier   \n",
       "...                            ...   \n",
       "4901                       hubpost   \n",
       "4902               itsshirleygreen   \n",
       "4903  tratomaseliasgonzalezbenitez   \n",
       "4904           alexjones8285-86083   \n",
       "4905                      gomezpai   \n",
       "\n",
       "                                           author_page  \\\n",
       "0                     https://medium.com/@anne.bonfert   \n",
       "1                         https://medium.com/@amy_burr   \n",
       "2                  https://medium.com/@cassady-fendlay   \n",
       "3                        https://medium.com/@shrinathv   \n",
       "4                   https://medium.com/@stephencasmier   \n",
       "...                                                ...   \n",
       "4901                       https://medium.com/@hubpost   \n",
       "4902               https://medium.com/@itsshirleygreen   \n",
       "4903  https://medium.com/@tratomaseliasgonzalezbenitez   \n",
       "4904           https://medium.com/@alexjones8285-86083   \n",
       "4905                      https://medium.com/@gomezpai   \n",
       "\n",
       "                                      subtitle responses  reading_time  \\\n",
       "0     Because I slipped on the tropical cliffs         0             9   \n",
       "1                                                      0             3   \n",
       "2                                                      0             6   \n",
       "3                                                      0             3   \n",
       "4                                                      0             7   \n",
       "...                                        ...       ...           ...   \n",
       "4901                                                   0             2   \n",
       "4902                                                   0             4   \n",
       "4903                                                   0             0   \n",
       "4904                                                   0             2   \n",
       "4905                                                   0             1   \n",
       "\n",
       "         tag        date  \n",
       "0     Travel  2022-01-01  \n",
       "1     Travel  2022-01-01  \n",
       "2     Travel  2022-01-01  \n",
       "3     Travel  2022-01-01  \n",
       "4     Travel  2022-01-01  \n",
       "...      ...         ...  \n",
       "4901  Travel  2022-02-16  \n",
       "4902  Travel  2022-02-16  \n",
       "4903  Travel  2022-02-16  \n",
       "4904  Travel  2022-02-16  \n",
       "4905  Travel  2022-02-16  \n",
       "\n",
       "[4906 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_df.to_csv('medium-data-travel.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
